{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "shauvy-petersen-notebookd140b45e58.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "xnCUPhb4mX2P"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import SnowballStemmer, PorterStemmer, LancasterStemmer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "#my imports\n",
        "#from sklearn import preprocessing\n",
        "#from sklearn import svm, datasets\n",
        "#from sklearn.model_selection import GridSearchCV\n",
        "#from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 842,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv_cCkvnjObT"
      },
      "source": [
        "## Load in your data from kaggle.\n",
        "By working in a kaggle kernel, you can access the data directly from the competition, as well as make your submission without downloading your output file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": false,
        "id": "f-9Qp3mCmX2V"
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "execution_count": 843,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeS0L_wRRA2t"
      },
      "source": [
        "## Cleaning up Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnKApuC_RAIf",
        "outputId": "ab0615a0-8ff5-43fa-d442-657e072fedab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
        "subs_url = r'url-web'\n",
        "train['message'] = train['message'].replace(to_replace = pattern_url, value = subs_url, regex = True)\n",
        "\n",
        "train['message'] = train['message'].str.lower()\n",
        "\n",
        "#print(string.punctuation)\n",
        "\n",
        "def remove_punctuation(message):\n",
        "    return ''.join([l for l in message if l not in string.punctuation])\n",
        "\n",
        "train['message'] = train['message'].apply(remove_punctuation)\n",
        "\n",
        "\"\"\"nltk.download(['punkt','stopwords'])\n",
        "stop_words = stopwords.words('english')\n",
        "#print(stop_words)\n",
        "def remove_stop_words(train):\n",
        "  txt = ''.join([l for l in train if l not in string.punctuation])\n",
        "  tokens = re.split('\\W+', train)\n",
        "  train = [t for t in tokens if t not in stop_words]\n",
        "  return train\"\"\""
      ],
      "execution_count": 844,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"nltk.download(['punkt','stopwords'])\\nstop_words = stopwords.words('english')\\n#print(stop_words)\\ndef remove_stop_words(train):\\n  txt = ''.join([l for l in train if l not in string.punctuation])\\n  tokens = re.split('\\\\W+', train)\\n  train = [t for t in tokens if t not in stop_words]\\n  return train\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 844
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66cjzy7XdHQW"
      },
      "source": [
        "#train['message'] = train['message'].apply(lambda x: remove_stop_words(x))"
      ],
      "execution_count": 845,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JRbiSEnRsr0",
        "outputId": "38d49119-d1a6-484d-f153-355accab4fe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#pd.set_option('display.max_colwidth', -1)\n",
        "train.head()\n"
      ],
      "execution_count": 846,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>message</th>\n",
              "      <th>tweetid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>polyscimajor epa chief doesnt think carbon dio...</td>\n",
              "      <td>625221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>its not like we lack evidence of anthropogenic...</td>\n",
              "      <td>126103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>rt rawstory researchers say we have three year...</td>\n",
              "      <td>698562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>todayinmaker wired  2016 was a pivotal year in...</td>\n",
              "      <td>573736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>rt soynoviodetodas its 2016 and a racist sexis...</td>\n",
              "      <td>466954</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                            message  tweetid\n",
              "0          1  polyscimajor epa chief doesnt think carbon dio...   625221\n",
              "1          1  its not like we lack evidence of anthropogenic...   126103\n",
              "2          2  rt rawstory researchers say we have three year...   698562\n",
              "3          1  todayinmaker wired  2016 was a pivotal year in...   573736\n",
              "4          1  rt soynoviodetodas its 2016 and a racist sexis...   466954"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 846
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_XHQcMXVsKs",
        "outputId": "b070dbb9-9d8e-4024-cde6-edc7d0329311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
        "subs_url = r'url-web'\n",
        "test['message'] = test['message'].replace(to_replace = pattern_url, value = subs_url, regex = True)\n",
        "\n",
        "test['message'] = test['message'].str.lower()\n",
        "\n",
        "#print(string.punctuation)\n",
        "\n",
        "def remove_punctuation(message):\n",
        "    return ''.join([l for l in message if l not in string.punctuation])\n",
        "\n",
        "test['message'] = test['message'].apply(remove_punctuation)\n",
        "\n",
        "\"\"\"nltk.download(['punkt','stopwords'])\n",
        "stop_words = stopwords.words('english')\n",
        "#print(stop_words)\n",
        "def remove_stop_words(test):\n",
        "  txt = ''.join([l for l in test if l not in string.punctuation])\n",
        "  tokens = re.split('\\W+', test)\n",
        "  test = [t for t in tokens if t not in stop_words]\n",
        "  return test\"\"\"\n"
      ],
      "execution_count": 847,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"nltk.download(['punkt','stopwords'])\\nstop_words = stopwords.words('english')\\n#print(stop_words)\\ndef remove_stop_words(test):\\n  txt = ''.join([l for l in test if l not in string.punctuation])\\n  tokens = re.split('\\\\W+', test)\\n  test = [t for t in tokens if t not in stop_words]\\n  return test\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 847
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q60_3D_dKuz"
      },
      "source": [
        "#test['message'] = test['message'].apply(lambda x: remove_stop_words(x))"
      ],
      "execution_count": 848,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqEDxD1iWJ0n",
        "outputId": "65af707a-7712-43f9-a9a3-573ae8394048",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#pd.set_option('display.max_colwidth', -1)\n",
        "test.head()"
      ],
      "execution_count": 849,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message</th>\n",
              "      <th>tweetid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>europe will now be looking to china to make su...</td>\n",
              "      <td>169760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>combine this with the polling of staffers re c...</td>\n",
              "      <td>35326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the scary unimpeachable evidence that climate ...</td>\n",
              "      <td>224985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>karoli morgfair osborneink dailykos \\nputin go...</td>\n",
              "      <td>476263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rt fakewillmoore female orgasms cause global w...</td>\n",
              "      <td>872928</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             message  tweetid\n",
              "0  europe will now be looking to china to make su...   169760\n",
              "1  combine this with the polling of staffers re c...    35326\n",
              "2  the scary unimpeachable evidence that climate ...   224985\n",
              "3  karoli morgfair osborneink dailykos \\nputin go...   476263\n",
              "4  rt fakewillmoore female orgasms cause global w...   872928"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 849
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwTAqfJixzP-"
      },
      "source": [
        "from sklearn.utils import resample\n",
        "believe = train[train['sentiment'] == 1]\n",
        "no_belief = train[train['sentiment'] == -1]\n",
        "neutral = train[train['sentiment'] == 0]\n",
        "news = train [train['sentiment'] == 2]\n",
        "class_size = (len(believe)-len(no_belief))/2\n",
        "new = int(class_size)\n",
        "#upsample minority\n",
        "no_belief_upsampled = resample(no_belief,\n",
        "                              replace=True, # sample with replacement\n",
        "                              n_samples=len(believe), #match number in majority class\n",
        "                              random_state=27) #reproducible results\n",
        "neutral_upsampled = resample(neutral,\n",
        "                              replace=True, # sample with replacement\n",
        "                              n_samples=len(believe), #match number in majority class\n",
        "                              random_state=27) #reproducible results\n",
        "news_upsampled = resample(news,\n",
        "                              replace=True, # sample with replacement\n",
        "                              n_samples=len(believe), #match number in majority class\n",
        "                              random_state=27) #reproducible results   \n",
        "#believe_downsampled = resample(believe,\n",
        " #                             replace=False, # sample with replacement\n",
        "  #                            n_samples=new, #match number in majority class\n",
        "   #                           random_state=27) #reproducible results   \n",
        "#combine majority and unsampled minority\n",
        "upsampled = pd.concat([believe, no_belief_upsampled,neutral_upsampled,news_upsampled])             "
      ],
      "execution_count": 850,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSROrtnj0tBw",
        "outputId": "72eda552-2bbd-44ed-b4ac-b5b33796ae9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "upsampled.sentiment.value_counts()"
      ],
      "execution_count": 851,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1    8530\n",
              " 2    8530\n",
              " 1    8530\n",
              " 0    8530\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 851
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WsUA0Zyvs2w",
        "outputId": "9e271f9c-0003-4364-b61e-d3ba8f8aadff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "train.sentiment.value_counts()"
      ],
      "execution_count": 852,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 1    8530\n",
              " 2    3640\n",
              " 0    2353\n",
              "-1    1296\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 852
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7So1SH25xB73"
      },
      "source": [
        "## Splitting out the X variable from the target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxWjr8GH1fpz"
      },
      "source": [
        "y = upsampled['sentiment']\n",
        "X = upsampled['message']"
      ],
      "execution_count": 853,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJUOYJj2xNXl"
      },
      "source": [
        "## Turning text into something your model can read"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nrx4Iy6vxOda"
      },
      "source": [
        "#vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=2, stop_words=\"english\") \n",
        "vocab = vectorizer.vocabulary_\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=2, stop_words=None, strip_accents = 'ascii', token_pattern = r'\\w{1,}', analyzer='word',smooth_idf=False,sublinear_tf=True,decode_error='ignore', encoding=str, vocabulary=vocab)\n",
        "X_vectorized = vectorizer.fit_transform(X)"
      ],
      "execution_count": 854,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptzNm8aixQy-"
      },
      "source": [
        "## Splitting the training data into a training and validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OAHcMs1xTie"
      },
      "source": [
        "#X_train,X_val,y_train,y_val = train_test_split(X_vectorized,y,test_size=.3,shuffle=True, stratify=y, random_state=11)\n",
        "X_train,X_val,y_train,y_val = train_test_split(X_vectorized,y,test_size=0.1,shuffle=True, stratify=y, random_state=11)"
      ],
      "execution_count": 855,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWZ5B_lLxV4s"
      },
      "source": [
        "## Training the model and evaluating using the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17-WbTBXxW1m"
      },
      "source": [
        "rfc = LogisticRegression(solver='newton-cg', C=4.7, random_state=0, fit_intercept=False , multi_class = 'ovr')\n",
        "rfc.fit(X_train, y_train)\n",
        "rfc_pred = rfc.predict(X_val)"
      ],
      "execution_count": 856,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKVVddMJxZaV"
      },
      "source": [
        "## Checking the performance of our model on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQteJHwlgkcQ",
        "outputId": "60606e7a-44c7-4e02-8cc8-3aceb277a108",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "print(\"The accuracy score of the model is:\", accuracy_score(y_val, rfc_pred))\n",
        "print(\"\\n\\nClassification Report:\\n\\n\",classification_report(y_val, rfc_pred))"
      ],
      "execution_count": 857,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy score of the model is: 0.9528135990621337\n",
            "\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.98      1.00      0.99       853\n",
            "           0       0.95      0.98      0.97       853\n",
            "           1       0.95      0.86      0.90       853\n",
            "           2       0.93      0.97      0.95       853\n",
            "\n",
            "    accuracy                           0.95      3412\n",
            "   macro avg       0.95      0.95      0.95      3412\n",
            "weighted avg       0.95      0.95      0.95      3412\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raG3XEl2xaRK",
        "outputId": "d9bc3bca-a6bd-47c8-c171-8b9da9a8de08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f1_score(y_val, rfc_pred, average=\"macro\")"
      ],
      "execution_count": 858,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9521392026204104"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 858
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYOVqeaSxcai"
      },
      "source": [
        "## Getting our test set ready"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWKUe1azxddT"
      },
      "source": [
        "testx = test['message']\n",
        "test_vect = vectorizer.transform(testx)"
      ],
      "execution_count": 859,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXwtiJyexgOS"
      },
      "source": [
        "## Making predictions on the test set and adding a sentiment column to our original test df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tg3ZFhvxhyv"
      },
      "source": [
        "y_pred = rfc.predict(test_vect)"
      ],
      "execution_count": 860,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utRFeaBCxjDk"
      },
      "source": [
        "test['sentiment'] = y_pred"
      ],
      "execution_count": 861,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mm3WmS3ZdlDK",
        "outputId": "03f6c83f-09e0-41c1-e0d2-1260bef728d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "test.sentiment.value_counts()"
      ],
      "execution_count": 862,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 1    6154\n",
              " 2    2630\n",
              " 0    1097\n",
              "-1     665\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 862
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1MsLryMxkPf",
        "outputId": "f7654817-4615-497d-d62d-f6b087342e3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 863,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message</th>\n",
              "      <th>tweetid</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>europe will now be looking to china to make su...</td>\n",
              "      <td>169760</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>combine this with the polling of staffers re c...</td>\n",
              "      <td>35326</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the scary unimpeachable evidence that climate ...</td>\n",
              "      <td>224985</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>karoli morgfair osborneink dailykos \\nputin go...</td>\n",
              "      <td>476263</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rt fakewillmoore female orgasms cause global w...</td>\n",
              "      <td>872928</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             message  tweetid  sentiment\n",
              "0  europe will now be looking to china to make su...   169760          1\n",
              "1  combine this with the polling of staffers re c...    35326          1\n",
              "2  the scary unimpeachable evidence that climate ...   224985          1\n",
              "3  karoli morgfair osborneink dailykos \\nputin go...   476263          1\n",
              "4  rt fakewillmoore female orgasms cause global w...   872928          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 863
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVvY-kFnxnhS"
      },
      "source": [
        "## Creating an output csv for submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZr0sO68xl9L"
      },
      "source": [
        "test[['tweetid','sentiment']].to_csv('Shauvy_Submission.csv', index=False)"
      ],
      "execution_count": 864,
      "outputs": []
    }
  ]
}